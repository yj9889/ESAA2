{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220328앙상블필사.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4jj1+0cHVU5TlncqSJKc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yj9889/ESAA2/blob/main/220328%EC%95%99%EC%83%81%EB%B8%94%ED%95%84%EC%82%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 핸즈온 머신러닝 - 07. 앙상블 학습과 랜덤 포레스트\n",
        "\n",
        "* 앙상블: 일련의 예측기로 예측을 수집해 가장 좋은 모델 하나보다 더 좋은 예측을 얻는 방법."
      ],
      "metadata": {
        "id": "18GEz99NAjYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 7.1 투표 기반 분류기\n",
        "* 직접 투표 분류기: 각 분류기의 예측을 모아 가장 많이 선택된 클래스 예측(다수결 투표)\n",
        "  * 앙상블은 예측기가 가능한 서로 독립적일 때 최고의 성능"
      ],
      "metadata": {
        "id": "MkLSGshrAtFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런 다수 분류기\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "pRDk9Fr2EO-3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS9dBxyMAbyd",
        "outputId": "03c60e95-bc71-49e5-e8fe-f145ca2459d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
              "                             ('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('svc', SVC(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# 선형 회귀 \n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "# 랜덤 포레스트\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# 서포트 벡터 머신\n",
        "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
        "\n",
        "# 다수결 분류기: 직접 투표 방식\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='hard')\n",
        "\n",
        "# 다수결 분류기 학습\n",
        "voting_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 분류기 별 정확도 측정\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__+':\\t', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TdquUstEBok",
        "outputId": "ddeea13f-7437-4ad0-f893-be2e1f22b694"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:\t 0.864\n",
            "RandomForestClassifier:\t 0.896\n",
            "SVC:\t 0.896\n",
            "VotingClassifier:\t 0.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 간접 투표: 모든 분류기가 클래스의 예측을 확인할 수 있으면(predict_proba() 메서드가 있으면), 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스 예측 가능\n",
        "  * *voting='hard'* -> *voting='soft'*\n",
        "  * SVC 기본값) *probability=True'*: SVC에서 predict_proba 사용 가능"
      ],
      "metadata": {
        "id": "ArcWAZKWEXrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 7.2 배깅과 페이스팅\n",
        "같은 알고리즘을 사용하고 훈련 세트의 서브셋을 무작위로 구성하여 분류기를 각기 다르게 학습시키는 것\n",
        "* 배깅: 훈련 세트에서 중복을 허용하여 샘플링하는 방식\n",
        "* 페이스팅: 훈련 세트에서 중복을 허용하지 않고 샘플링하는 방식 \n",
        "  * 분류) 통계적 최빈값\n",
        "  * 회귀) 평균\n",
        ">> ## 7.2.1 사이킷런의 배깅과 페이스팅\n",
        "* 분류) *BaggingClassifier* \n",
        "* 회귀) *BaggingRegressor*"
      ],
      "metadata": {
        "id": "_HhXld3PAvwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(random_state=42), \n",
        "    n_estimators=500,\n",
        "    max_samples=100, \n",
        "    # bootstrap=True 가 기본값임.\n",
        "#     bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "TIYaLcRlAzlu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmS6GaAfGT2P",
        "outputId": "7e7c23a6-5af1-4836-e0ec-21b3d435bdaf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred_tree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqMmwE8WGWb-",
        "outputId": "a993ebbb-9e39-407e-c6cf-498c4d7438bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> ## 7.2.2 oob 평가\n",
        "* 배깅을 사용하면 한 번도 선택되지 못하는 샘플이 존재, 뽑히지 않을 확률은 37% 정도\n",
        "* oob샘플: 선택되지 않은 훈련 샘플\n",
        "  * 사이킷런) BaggingClassifier 에 *oob_score=True*옵션"
      ],
      "metadata": {
        "id": "Ah6ZQ_WwAz0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), \n",
        "    n_estimators=500, \n",
        "    bootstrap=True, \n",
        "    n_jobs=-1,\n",
        "    oob_score=True)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "bag_clf.oob_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF3_ecunA8JY",
        "outputId": "922fcae5-4d1b-4dd6-e506-703d28f8755b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9013333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "128tsuyVG-0A",
        "outputId": "570c47c0-9747-4187-8118-e7aff4c003e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.904"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.oob_decision_function_[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Da1BWMXHPZC",
        "outputId": "9e9c0a5c-25d9-439e-d9c4-2c357b8720c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42696629, 0.57303371],\n",
              "       [0.30810811, 0.69189189],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00549451, 0.99450549],\n",
              "       [0.0887574 , 0.9112426 ],\n",
              "       [0.37234043, 0.62765957],\n",
              "       [0.00505051, 0.99494949],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98351648, 0.01648352]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 7.3 랜덤 배치와 랜덤 서브스페이스\n",
        "특성을 대상으로 하는 두 파라미터\n",
        "* max_features: 학습에 사용할 특성 수를 지정\n",
        "* bootstrap_features: 학습에 사용할 특성을 선택할 때 중복 허용 여부 지정\n",
        "\n",
        "* 랜덤 패치 방식: 훈련 특성과 샘플을 모두 샘플링\n",
        "* 랜덤 서브스페이스 방식: 훈련 샘플은 모두 사용하고 특성은 샘플링\n",
        "  * 훈련 샘플 모두) *bootstrap=False, max_sample=0.1*\n",
        "  * 특성 샘플링) *bootstrap_features=True, max_features=0.1보다 작게*: 더 다양한 예측기, 편향을 늘리는 대신 분산 낮춤"
      ],
      "metadata": {
        "id": "mltQhmg5A8dT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 7.4 랜덤 포레스트\n",
        "* BaggingClassifier에 DecisionTreeClassifier를 넣어 만드는 대신, RandomForestClassifier 사용\n"
      ],
      "metadata": {
        "id": "3PcI_uGDBE-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(\n",
        "    n_estimators=500, # 500개의 의사결정나무 학습\n",
        "    max_leaf_nodes=16, # 사용되는 의사결정나무의 잎의 수를 16개로 제한\n",
        "    n_jobs=-1) # 가용 가능한 모든 CPU 사용\n",
        "\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "89bQkVkpIWXd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf_auto = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16),\n",
        "    n_estimators=500,\n",
        "    # max_samples=1.0 이 기본값임.\n",
        "    max_samples=1.0, \n",
        "    # bootstrap=True 가 기본값임.\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)"
      ],
      "metadata": {
        "id": "mIgUTX5gJyAa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> ## 7.4.1 엑스트라 트리\n",
        "* 익스트림 랜덤 트리: 극단적으로 무작위한 트리의 랜덤 트리\n",
        "  * 편향 늘지만, 분산 줄음\n",
        "  * *ExtraTreesClassifier*\n",
        "\n",
        ">> ## 7.4.2 특성 중요도\n",
        "* 랜덤 포레스트는 학습에 사용된 특성의 상대적 중요도도 함께 측정한다. 특성 중요도는 해당 특성을 사용한 마디가 평균적으로 불순도를 얼마나 감소시키는지를 측정한다. 즉, 불순도를 많이 줄이면 그만큼 중요도가 커진다.\n",
        "  * 가중치(각 노드의 연관된 훈련 샘플 수) 평균\n",
        "* 사이킷런의 RandomForestClassifier는 훈련이 끝난 뒤 특성별 중요도의 전체 합이 1이 되도록 하는 방식으로 특성별 상대적 중요도를 측정한 후 feature_importances_ 속성에 저장"
      ],
      "metadata": {
        "id": "vmFjMOgBKB6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
        "\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "    print(name, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKF85lXVKyOr",
        "outputId": "8e49906f-d061-46b0-fa38-75d41cd9630d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.11249225099876375\n",
            "sepal width (cm) 0.02311928828251033\n",
            "petal length (cm) 0.4410304643639577\n",
            "petal width (cm) 0.4233579963547682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 7.5 부스팅\n",
        "* 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법\n",
        ">> ## 7.5.1 에이다부스트\n",
        "* 이전 모델이 과소적합했던 훈련 샘플의 가중치를 높여 새로운 예측기는 학습하기 어려운 샘플에 점점 더 맞춰짐.\n",
        "  * cf. 경사 하강법: 비용 함수를 최소화하기 위해 한 예측기의 모델 파라미터 조정 <-> 에이다부스트: 앙상블에 예측기 추가"
      ],
      "metadata": {
        "id": "BbApcff4BMqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), \n",
        "    n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", \n",
        "    learning_rate=0.5, \n",
        "    random_state=42)\n",
        "\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfyaz_JDL6-f",
        "outputId": "dd9fa57e-7fec-4bb2-9576-5d4025d02ed8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   learning_rate=0.5, n_estimators=200, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 7.5.2 그레이디언트 부스팅\n",
        "* 반복마다 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 **잔여 오차**에 새로운 예측기 학습시킴."
      ],
      "metadata": {
        "id": "ribjTbElBRDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)\n",
        "\n",
        "# 의사결정나무 회귀모델을 이용하여 학습\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg1.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5yrBhwqOMNK",
        "outputId": "c605375b-1be7-49a4-9e8c-ab4a27bb8fc0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측기의 예측 결과와의 오차에 대한 레이블을 대상으로 의사결정나무 회귀모델 학습\n",
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHW1bZykOR-b",
        "outputId": "a55256fc-e43f-48d7-e507-3755b2c740c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측기의 예측 결과와의 오차에 대한 레이블을 대상으로 의사결정나무 회귀모델 학습\n",
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AupN8XtVObcO",
        "outputId": "3d75e36b-f032-4f94-b6ed-e8fb2ca94beb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 샘플\n",
        "X_new = np.array([[0.8]])\n",
        "# 모든 예측값 더하기\n",
        "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
      ],
      "metadata": {
        "id": "O-YnCW1oOgGS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *GradientBoostingRegressor*: n_estimators, max_depth, min_samples_leaf 등으로 조절"
      ],
      "metadata": {
        "id": "kGxUjPZTPLMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
        "gbrt.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx8F8YGyPIDy",
        "outputId": "28c3c2d1-8179-455a-d11a-f0df14f8f1b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3,\n",
              "                          random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **축소**: *learning_rate*를 낮게 설정하면 앙상블을 훈련 세트에 학습시키기 위해 많은 트리가 필요하지만 예측 성능이 좋아짐.\n",
        "\n",
        "* 최적의 트리 찾기: 조기 종료 기법\n",
        "  * staged_predict()\n",
        "  * *warm_start=True*: 사이킷런이 fit() 메서드가 호출될 때 기존 트리를 유지하고 훈련을 추가할 수 있도록 함.\n"
      ],
      "metadata": {
        "id": "L__Ou4VlPYsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 이전 학습 내용을 지우고 새로 훈련하기 위해 훈련 세트 섞기. \n",
        "# random_state를 다른 값으로 지정.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)\n",
        "\n",
        "# GBRT 모델 설정 및 훈련\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "# staged_predict()에 의해 생성된 반복자를 활용하여\n",
        "# 각 단계별 MSE 수집 후 최소값을 갖는 인덱스 확인\n",
        "errors = [mean_squared_error(y_val, y_pred)\n",
        "          for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "# 최적의 의사결정나무 수를 이용하여 새로 학습\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, random_state=42)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_oFsz_yPv5i",
        "outputId": "3905565c-3128-4d95-d25e-d5d01435baae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=56, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 확률적 그레디언트 부스팅: 훈련 샘플의 비율을 지정할 수 있는 subsample 사용하여 적은 비율의 훈련샘플 사용하면 편향 높아지는 대신 분산 낮아짐"
      ],
      "metadata": {
        "id": "PKx26BRUP9FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "xgb_reg = xgboost.XGBRegressor(random_state=42)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCxMEdurQVHu",
        "outputId": "47cbceed-5a09-4353-8c2e-3089a1276b96"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_reg.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds=2)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG1XzGfpQk9i",
        "outputId": "912d53e7-9e75-4f5b-f7d4-e38c2a26f994"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:0.286719\n",
            "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
            "[1]\tvalidation_0-rmse:0.258221\n",
            "[2]\tvalidation_0-rmse:0.232634\n",
            "[3]\tvalidation_0-rmse:0.210526\n",
            "[4]\tvalidation_0-rmse:0.190232\n",
            "[5]\tvalidation_0-rmse:0.172196\n",
            "[6]\tvalidation_0-rmse:0.156394\n",
            "[7]\tvalidation_0-rmse:0.142241\n",
            "[8]\tvalidation_0-rmse:0.129789\n",
            "[9]\tvalidation_0-rmse:0.118752\n",
            "[10]\tvalidation_0-rmse:0.108388\n",
            "[11]\tvalidation_0-rmse:0.100155\n",
            "[12]\tvalidation_0-rmse:0.09208\n",
            "[13]\tvalidation_0-rmse:0.084791\n",
            "[14]\tvalidation_0-rmse:0.078699\n",
            "[15]\tvalidation_0-rmse:0.073248\n",
            "[16]\tvalidation_0-rmse:0.069391\n",
            "[17]\tvalidation_0-rmse:0.066277\n",
            "[18]\tvalidation_0-rmse:0.063458\n",
            "[19]\tvalidation_0-rmse:0.060326\n",
            "[20]\tvalidation_0-rmse:0.0578\n",
            "[21]\tvalidation_0-rmse:0.055643\n",
            "[22]\tvalidation_0-rmse:0.053943\n",
            "[23]\tvalidation_0-rmse:0.053138\n",
            "[24]\tvalidation_0-rmse:0.052415\n",
            "[25]\tvalidation_0-rmse:0.051821\n",
            "[26]\tvalidation_0-rmse:0.051226\n",
            "[27]\tvalidation_0-rmse:0.051135\n",
            "[28]\tvalidation_0-rmse:0.05091\n",
            "[29]\tvalidation_0-rmse:0.050893\n",
            "[30]\tvalidation_0-rmse:0.050725\n",
            "[31]\tvalidation_0-rmse:0.050471\n",
            "[32]\tvalidation_0-rmse:0.050285\n",
            "[33]\tvalidation_0-rmse:0.050492\n",
            "[34]\tvalidation_0-rmse:0.050348\n",
            "Stopping. Best iteration:\n",
            "[32]\tvalidation_0-rmse:0.050285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 7.6 스태킹\n",
        "* 앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수(like 직접 투표) 대신 취합하는 모델을 훈련시킴."
      ],
      "metadata": {
        "id": "BHAn2isIBVhV"
      }
    }
  ]
}