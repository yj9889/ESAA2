{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220509텍스트분석2.ipynb",
      "provenance": [],
      "mount_file_id": "1xUB6h78RunVBGLVfK9GKq9zO5oDysTF0",
      "authorship_tag": "ABX9TyPZNb9vNVnIb2rRn9LBwvPn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yj9889/ESAA2/blob/main/220509%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B6%84%EC%84%9D2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파이썬 머신러닝 완벽 가이드 p512-516,529-543"
      ],
      "metadata": {
        "id": "KqpfvATDH4vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 06. 토픽 모델링 - 20 뉴스그룹"
      ],
      "metadata": {
        "id": "R7gFjE6DIXuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 토픽 모델링: 문서 집합에 숨어 있는 주제를 찾아 내는 것. 숨겨진 주제를 효과적으로 표현할 수 있는 중심 단어를 함축적으로 추출\n",
        "  * LDA(Latent Dirichlet Allocation) \n",
        "    * LSA(Latent Semantic Analysis)도 존재"
      ],
      "metadata": {
        "id": "bdMbepI-Ity6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi4SgLZKHzIO",
        "outputId": "7fdd30b2-eccb-4190-a7d9-9d4ef98dc57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer Shape: (7862, 1000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 의학, 우주 주제를 추출. \n",
        "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
        "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
        "\n",
        "# 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력\n",
        "news_df= fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'), \n",
        "                            categories=cats, random_state=0)\n",
        "\n",
        "#LDA 는 Count기반의 Vectorizer만 적용합니다.  \n",
        "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
        "feat_vect = count_vect.fit_transform(news_df.data)\n",
        "print('CountVectorizer Shape:', feat_vect.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
        "lda.fit(feat_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fmbBjYOJOPK",
        "outputId": "87eb20ad-24f8-456c-d54d-136699c3fd24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=8, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lda.components_.shape) #높은 값일수록 토픽의 중심 word\n",
        "lda.components_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-al8jZMAJOMv",
        "outputId": "22a77577-145f-49b0-c7e5-01b125010ead"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 1000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
              "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
              "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
              "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
              "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
              "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
              "       ...,\n",
              "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
              "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
              "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
              "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
              "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
              "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_index, topic in enumerate(model.components_):\n",
        "        print('Topic #',topic_index)\n",
        "\n",
        "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환. \n",
        "        topic_word_indexes = topic.argsort()[::-1]\n",
        "        top_indexes=topic_word_indexes[:no_top_words]\n",
        "        \n",
        "        # top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
        "        feature_concat = ' '.join([feature_names[i] for i in top_indexes])                \n",
        "        print(feature_concat)\n",
        "\n",
        "# CountVectorizer객체내의 전체 word들의 명칭을 get_features_names( )를 통해 추출\n",
        "feature_names = count_vect.get_feature_names()\n",
        "\n",
        "# Topic별 가장 연관도가 높은 word를 15개만 추출\n",
        "display_topics(lda, feature_names, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlJUyUGaJOKf",
        "outputId": "c75ef645-3ae3-4ccc-9a75-9ccb0fda7abf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic # 0\n",
            "year 10 game medical health team 12 20 disease cancer 1993 games years patients good\n",
            "Topic # 1\n",
            "don just like know people said think time ve didn right going say ll way\n",
            "Topic # 2\n",
            "image file jpeg program gif images output format files color entry 00 use bit 03\n",
            "Topic # 3\n",
            "like know don think use does just good time book read information people used post\n",
            "Topic # 4\n",
            "armenian israel armenians jews turkish people israeli jewish government war dos dos turkey arab armenia 000\n",
            "Topic # 5\n",
            "edu com available graphics ftp data pub motif mail widget software mit information version sun\n",
            "Topic # 6\n",
            "god people jesus church believe christ does christian say think christians bible faith sin life\n",
            "Topic # 7\n",
            "use dos thanks windows using window does display help like problem server need know run\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "topic 0, 5, 7은 애매\n",
        "\n",
        "1: 컴퓨터 그래픽스\n",
        "\n",
        "2: 기독교\n",
        "\n",
        "3: 의학\n",
        "\n",
        "4: 윈도우 운영체제\n",
        "\n",
        "6: 중동 분쟁\n",
        "\n",
        "- 모토사이클, 야구는 명확한 주제어가 추출x\n"
      ],
      "metadata": {
        "id": "dM5BTyNYJh2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 08. 문서 유사도"
      ],
      "metadata": {
        "id": "L_3BfsNTKX63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **문사 유사도 측정 방법 - 코사인 유사도**\n",
        "  + 벡터와 벡터 간의 유사도를 비교할 때 벡터의 크기보다는 벡터의 상호 방향성이 얼마나 유사한지 기반\n",
        "두 벡터의 사잇각을 구해 얼마나 유사한지 수치로 적용한 것\n",
        "\n",
        "* **두 벡터 사잇각**\n",
        "  * A*B = |A||B|cosθ\n",
        "  * similarity = A*B / |A||B|\n",
        "\n",
        "* 장점\n",
        "\n",
        "문서를 피처 벡터화 변환하면 차원이 매우 많은 희소 행렬이 되기 쉬운데, 이때 문서와 문서 벡터간 크기 기반 유사도 지표는 정확도가 떨어지기 쉽다.\n",
        "또한, 문서가 매우 긴 경우 단어의 빈도수도 많을 것이라서 빈도수에만 기반해서는 공정한 비교를 할 수 없다.\n"
      ],
      "metadata": {
        "id": "puPyuD-ZKZ1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0bwyJ0YJOFB",
        "outputId": "96035e0d-0f94-40fa-c371-cc11c5646138"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cos_similarity(v1, v2):\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    l2_norm = (np.sqrt(sum(np.square(v1))) * np.sqrt(sum(np.square(v2))))\n",
        "    similarity = dot_product / l2_norm     \n",
        "    \n",
        "    return similarity"
      ],
      "metadata": {
        "id": "j3mY12E7JOCf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "doc_list = ['if you take the blue pill, the story ends' ,\n",
        "            'if you take the red pill, you stay in Wonderland',\n",
        "            'if you take the red pill, I show you how deep the rabbit hole goes']\n",
        "\n",
        "tfidf_vect_simple = TfidfVectorizer()\n",
        "feature_vect_simple = tfidf_vect_simple.fit_transform(doc_list)\n",
        "print(feature_vect_simple.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_GfZhJeLYMg",
        "outputId": "050acfd8-7987-4a3b-c608-d5bb09808151"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TFidfVectorizer로 transform()한 결과는 Sparse Matrix이므로 Dense Matrix로 변환. \n",
        "feature_vect_dense = feature_vect_simple.todense()\n",
        "\n",
        "#첫번째 문장과 두번째 문장의 feature vector  추출\n",
        "vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
        "vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
        "\n",
        "#첫번째 문장과 두번째 문장의 feature vector로 두개 문장의 Cosine 유사도 추출\n",
        "similarity_simple = cos_similarity(vect1, vect2 )\n",
        "print('문장 1, 문장 2 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONhUndJ0Lc8E",
        "outputId": "7b7b77a8-88fc-4880-acb7-9eadcc2ea686"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 1, 문장 2 Cosine 유사도: 0.402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
        "vect3 = np.array(feature_vect_dense[2]).reshape(-1,)\n",
        "similarity_simple = cos_similarity(vect1, vect3 )\n",
        "print('문장 1, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))\n",
        "\n",
        "vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
        "vect3 = np.array(feature_vect_dense[2]).reshape(-1,)\n",
        "similarity_simple = cos_similarity(vect2, vect3 )\n",
        "print('문장 2, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvyaH73aLc5k",
        "outputId": "3782a07c-2d1e-4e7b-8a4d-153e6264c3bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 1, 문장 3 Cosine 유사도: 0.404\n",
            "문장 2, 문장 3 Cosine 유사도: 0.456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_simple_pair = cosine_similarity(feature_vect_simple[0] , feature_vect_simple)\n",
        "print(similarity_simple_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yeMzPpMLc3M",
        "outputId": "f3772c1d-2ece-4a33-a78c-0eac93ee6f8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.40207758 0.40425045]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_simple_pair = cosine_similarity(feature_vect_simple[0] , feature_vect_simple[1:])\n",
        "print(similarity_simple_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5fZayieLc0z",
        "outputId": "fd32998a-086e-4017-a0ee-7ac089212f10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.40207758 0.40425045]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_simple_pair = cosine_similarity(feature_vect_simple , feature_vect_simple)\n",
        "print(similarity_simple_pair)\n",
        "print('shape:',similarity_simple_pair.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHgfy9afLcyh",
        "outputId": "ef2df680-ff63-448a-d9f9-04802a71b35c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.40207758 0.40425045]\n",
            " [0.40207758 1.         0.45647296]\n",
            " [0.40425045 0.45647296 1.        ]]\n",
            "shape: (3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Opinion Review 데이터 셋을 이용한 문서 유사도 측정**"
      ],
      "metadata": {
        "id": "6bq3ZztfLugc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "lemmar = WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmar.lemmatize(token) for token in tokens]\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "uGb0ZdA8LcrX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob ,os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "path = r'/content/drive/MyDrive/data/OpinosisDataset1.0/topics'\n",
        "all_files = glob.glob(os.path.join(path, \"*.data\"))     \n",
        "filename_list = []\n",
        "opinion_text = []\n",
        "\n",
        "for file_ in all_files:\n",
        "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
        "    filename_ = file_.split('\\\\')[-1]\n",
        "    filename = filename_.split('.')[0]\n",
        "    filename_list.append(filename)\n",
        "    opinion_text.append(df.to_string())\n",
        "\n",
        "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \\\n",
        "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )\n",
        "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
        "\n",
        "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
        "km_cluster.fit(feature_vect)\n",
        "cluster_label = km_cluster.labels_\n",
        "cluster_centers = km_cluster.cluster_centers_\n",
        "document_df['cluster_label'] = cluster_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF7WOsmwLylb",
        "outputId": "9df06f20-773e-4238-a1ad-4d41e68af916"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# cluster_label=1인 데이터는 호텔로 클러스터링된 데이터임. DataFrame에서 해당 Index를 추출\n",
        "hotel_indexes = document_df[document_df['cluster_label']==1].index\n",
        "print('호텔로 클러스터링 된 문서들의 DataFrame Index:', hotel_indexes)\n",
        "\n",
        "# 호텔로 클러스터링된 데이터 중 첫번째 문서를 추출하여 파일명 표시.  \n",
        "comparison_docname = document_df.iloc[hotel_indexes[0]]['filename']\n",
        "print('##### 비교 기준 문서명 ',comparison_docname,' 와 타 문서 유사도######')\n",
        "\n",
        "''' document_df에서 추출한 Index 객체를 feature_vect로 입력하여 호텔 클러스터링된 feature_vect 추출 \n",
        "이를 이용하여 호텔로 클러스터링된 문서 중 첫번째 문서와 다른 문서간의 코사인 유사도 측정.'''\n",
        "similarity_pair = cosine_similarity(feature_vect[hotel_indexes[0]] , feature_vect[hotel_indexes])\n",
        "print(similarity_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIkVha1BL0aW",
        "outputId": "4967046e-c54d-42c8-beb8-4899d589db20"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "호텔로 클러스터링 된 문서들의 DataFrame Index: Int64Index([4, 5, 7, 8, 10, 17, 22, 23, 24, 25, 28, 30, 32, 40, 41, 45], dtype='int64')\n",
            "##### 비교 기준 문서명  /content/drive/MyDrive/data/OpinosisDataset1  와 타 문서 유사도######\n",
            "[[1.         0.94217517 0.27745184 0.24515472 0.27523861 0.19544761\n",
            "  0.14589696 0.06487772 0.25016153 0.27181547 0.14355714 0.17331798\n",
            "  0.09611626 0.07508644 0.06562183 0.07049362]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# argsort()를 이용하여 앞예제의 첫번째 문서와 타 문서간 유사도가 큰 순으로 정렬한 인덱스 반환하되 자기 자신은 제외. \n",
        "sorted_index = similarity_pair.argsort()[:,::-1]\n",
        "sorted_index = sorted_index[:, 1:]\n",
        "\n",
        "# 유사도가 큰 순으로 hotel_indexes를 추출하여 재 정렬. \n",
        "hotel_sorted_indexes = hotel_indexes[sorted_index.reshape(-1)]\n",
        "\n",
        "# 유사도가 큰 순으로 유사도 값을 재정렬하되 자기 자신은 제외\n",
        "hotel_1_sim_value = np.sort(similarity_pair.reshape(-1))[::-1]\n",
        "hotel_1_sim_value = hotel_1_sim_value[1:]\n",
        "\n",
        "# 유사도가 큰 순으로 정렬된 Index와 유사도값을 이용하여 파일명과 유사도값을 Seaborn 막대 그래프로 시각화\n",
        "hotel_1_sim_df = pd.DataFrame()\n",
        "hotel_1_sim_df['filename'] = document_df.iloc[hotel_sorted_indexes]['filename']\n",
        "hotel_1_sim_df['similarity'] = hotel_1_sim_value\n",
        "\n",
        "sns.barplot(x='similarity', y='filename',data=hotel_1_sim_df)\n",
        "plt.title(comparison_docname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "XLbStVnrNlyE",
        "outputId": "2568e7bd-5f56-44b5-b6f1-94f19b0862b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '/content/drive/MyDrive/data/OpinosisDataset1')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAEWCAYAAAAqz5CSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhkVXm28fsBBJXZ4CcCSoOiCTiAwVmw/ZyAiMYZ44iahCRKjPNAFIdEAomJoolxiiIqqJ8a1IiKAiKOgCiKQWZlEAWZFWR4vz/WOnR1cYY63X1696Hv33XV1VW79vDuXbtrP2etVVWpKiRJkjSMdYYuQJIkaW1mGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMklaDJMclefEszz87yVdWZ02rQ5KfJFm6GrYz6/Fd0yR5b5K/X+BtXJNk+4XchlYNw5ikwSXZKskFC7j+A5McvgrXN+2FP8lDk3xrRdZZVR+rqsetfHW31PLlJI/r+15J/nbs+b/t0w+cYF1L+rzX9NslSb6Q5LFzLVtVO1XVcSu+J8vVscLHd2w95yV5zAosd0aSe/X7D0vy9SRXJ7kyyeeT7Djpuqpqv6p663xrmI+q2qiqzpltniRLk9w88tpekOSTSR446XZW9f+v+WwnyTOSfCvJb5Mct9A1LBTDmKQ1wV7A0UMXsQr8CfA/810oyXqrsogkGwK7Asf3ST8Dnjc22/P79PnYrKo2Au4PfBX4bJIXzFDDKt2nboWO76qQ5B7AulX1syQPBb4C/DewFbAd8EPgxEXaEnVRf103Bh4C/C9wQpJHD1vWRH4D/Btw0NCFrJSq8ubNm7dBb8BngKf0+3frj38NXAa8u09fBzgAOB/4FXAYsGl/bglQtIDxc+BS4A39uT2A3wM3ANcAP+zTNwU+CFwMXAi8jXaxBXgB8E3gn4HLgXOBPftz/wDcBFzX1/fukf04BXhAv/9Y2kXtSuDdtGD04pH1nwj8a9/Ht01tsz//H8A/jx2j/wZe3u9vBfy/fozOBfYfm/eJwFH9/oHA4cBPgZ36tJ2A0/v0A/u0HwN7j6zjdv047jJyfNcb284rgUuAdfrj84DXAD8CrgfW69Me02v+HXCnkeV36du4XX/8wl7n5cCXgW3Htjfp8b0H8PV+bC8FPkYLkgAfBW7utVwDvLpP/xTwy76+b0wdq5Ft7w+8q98/Afj3ac7jLwGH9ftLgQuA1/cazgOePTLvh4G3jc37Ctq5fTGw78i8m9LO91/Tzv8DRo75Pfu+X9m3c+TIcgXcs9/fq7/mV9PO91eObnuafXk3cNLI43cCvwCuAk4Gdpvj/9e+/bW8GjgH+MuRdW0BfAG4ghamThjZn2nP7Zm2M7LOFwPHDf1etqI3W8YkDSrJ7YDdga8mWZf2Jn0+LQBsDRzRZ31Bvz0K2B7YiHbBGPUI4N7Ao4E3Jvmjqjoa+EfaRWqjqrp/n/fDwI20i9kuwONob+hTHgycQbtwHAx8MEmq6g20i8dL+vpe0vfjrsBdgB8k2YIWKA/oy58NPHys1gfTLlJ3oQW8UZ8Anpkkfd2b9/qOSLIO8HlaS8zWfV9fluTxI8vvBXxxbJ0fZVnr2PP741GHAc8ZW8fFVfUDZvYZ4P/QjvmUZ9FasDarqhunJlbVRcC3gaeOzPtnwKer6oYkT6IFl6cAd6Yd409MzTjP4xvg7bQL+x/RAv6BvY7n0gL73v31O7gv8yVgh74/p9AC3Ki9gC8muSPwMFp4G/dJWkicsmWvb2vaMX9fkntPs9zUvJv2eV8EvKe/7gCH9ue2Bx5Jex337c+9ldZKtzmwTZ93Oh+kBaKNgfvQwupsPgM8oLeyAnwf2Bm4E/Bx4FNJbj/L/69fAU8ANum1/muSB/TnXkELn3emvaavB2q2c3uW7dwmGMYkDW132l+5VwMPol1AX1VV11bVdVX1zT7fs4F3VNU5VXUN8Dpgn7HusDdX1e+q6oe0N/Rp37CT3IV2cX1Z386vaK1U+4zMdn5Vvb+qbgI+AkyFgZnsBRxd7c/0vYCfVNWnq+oGWjfKL8fmv6iqDq2qG6vqd2PPnUBr1ditP34a8O0eaB4I3Lmq3lJVv682Juj9Y7Xvxa278w4HntXD7z798fjzeyXZpD9+LrcObOMu6v/eaWTau6rqF9PsE7SL+LMAetDcp08D2A94e1X9tIe4fwR2TrLtyD5NdHyr6qyq+mpVXV9VvwbeQQsxM6qqD1XV1VV1PS243T/Jpr3WO9KO+3F9X9ehtV6Nu5gWvkb9fa/jeFpAfsYMJdwAvKWqbqiq/6G1/ty7/4GyD/C6Xt95wL/QXp+p5bYFthr7/zLd+ndMsklVXV5Vp8x2PGivbYDNAKrq8Kq6rJ+v/wJswPIhfDlV9cWqOrua42mBcep8voH2/2nbvr8n9Nd1knP7NskwJmloo8HhbrQQdOM0821FazGbcj6tG2w0II0Gnt/SWs+msy2tG+7iJFckuQL4T1qryK3WVVW/7XdnWt/4fmxF69KZWr5GH3fjj2/R5z+CHlxoLUhTLTXbAltN1d1rfz39OCS5L3BlVf1ibJ0/B86ihZwzp3n+IlrX6VOTbAbsya1bh8Zt3f/9zST7Ret+emhv5dqd1l14wsh+vXNkn35DCwNT25j4+Ca5S5IjklyY5Cpa0BwPSYzMv26Sg5Kc3ec/rz81tcyjgW/1oHZ5r/uu06zqrrSuwimXV9W1I4/P77VP57Kx837q/N2Cdq6On/tTx+XVtOP0vf7J1RfOsP6n0o7h+UmO7+PeZrM17Q+CKwCSvDLJT/uHFa6gtdTNdkz3TPKdJL/p8+81Mv8htHPxK0nOSfLaPn3Wc/u2bCEGWErSfOxF65qCdkG9e5L1pglkF9HerKfcndbNeAmte2Y2Nfb4F7QxTVvMEPzmstz6emvTI1nWdXQxLVhOPZ/RxzPUNO4TtIvVQbQuzSeP1H5uVe0ww3LTtYpNOQz40Eid4z5C66pdj9YSd+EcNT6Z1h11xsi0Gferqi5P+/qOZ9K6D4/oQQrafv1DVd0qAK7A8f3HXsd9q+o3Sf6U5bu0x2v8M+BJtLFt59GCxuW0kAMjx7Sqrk3ybeDpwLFj63kG8LWRx5sn2XAkkN2dNjZvPi5lWevX6SPrubDX80vgzwGSPAI4Jsk3quqs0ZVU1feBJ/Vj+RJal+r4OTnqycApfX93o4W+R9NaJG9OMnp8xv8/bEAL3s8D/rt3Q39uav7eCv4K4BVJ7gN8Pcn3mfvcnuv/zKJly5ikwSTZDtigqn7aJ32PdqE9KMmGSW6fZGos0CeAv0uyXZKNWDZ+ZJIwdQmwpI9JoaoupnWb/EuSTZKsk+QeSWbtyhpb3+in5h4B/KiqruqPvwjslOQpvRt1f9qYoIn1sVqXAh8AvlxVV/SnvgdcneQ1Se7QW3XuM/JVBNONF5tyJG3s2SdneP5zwAOAv6UFt2n1lqeXAG+idZ/dPI9d+zjtIv00lnVRArwXeF2Snfo2Nk3y9P7cfI/vxrRuviuTbA28aqyG8ddvY1o4vwy4I+3cGrUnyx/T1wLPT7J/ko2TbJ7kbcBDgTePLfvmJOv3QPMEph9rNqPeTf5J4B/6trYFXk7vZk7y9CRTf4xcTgssy70effvPTrJp79a9anyePl+SbJ3kTbRQ/vr+1Ma0P3x+DayX5I20sWBTlvv/BaxP68b8NXBjkj1p593Udp6Q5J49RF9J+0DMzcx9bo9vZ6pV8/a0PyDW6e8Zt5vk2K5JDGOShrTcVxX0C8/etEH1P6cN8n1mf/pDtDFM36B9yuo64KUTbmfqAnhZkqmxMs+jXTROp13EPs30XU/TeSfwtCSXJ3nXNPtxKa3l5CDaBX4HWhfgfH2c1lpzS2jpx+gJtMHU57IssG3auxd3BKb9Lq4+nu6YGcZz0af/P9pXNXxmmlmuSHItcBot9D29qj40z306inY8ftnH9k1t+7PAP9E+pHAVrQVpz/70fI/vm2mh8kpaiBrfl7cDB/SusFfSguf5tNam04HvTM3YW26u6d28U9v/JvB4WovuxX3ZXYBHVNWZI9v5Je3cuojW5btfVf3vREdpeS8FrqV94OObtPNh6rg/EPhukmtox/Zva/rvFnsucF4/tvvRxmBO2aovfw1toP59gaVVNfUlxF+mffXMz/q+Xsfy3dHL/f/qLV/700Lk5bSWx6NG5t8BOKZv79u0T6YeO9u5Pd12Rvbrd7RPIO/W779/mv1fo2VZC7EkrV5J/of21RCDfHfUqpLkdOBpVXX6nDMvbB3P6HXMNEh8knW8EbhXVT1nzplXkyGPb5JX07qzXz3P5ZYCh1fVXF3okmPGJA3qOG497mZRSbI+7bulBg1i3RW0T4WukCR3on2twnPnmnd1WQOO73m0r1uQFowtY5Ikkvw57SsiPlpV+w1dz2Jny5jmwzAmSZI0IAfwS5IkDcgxY5JuscUWW9SSJUuGLkOSFpWTTz750qq684oubxiTdIslS5Zw0kknDV2GJC0qSc6fe66Z2U0pSZI0IMOYJEnSgAxjkiRJAzKMSZIkDcgwJkmSNCDDmCRJ0oAMY5IkSQMyjEmSJA3IMCZJkjQgw5gkSdKADGOSJEkDMoxJkiQNyDAmSZI0IMOYJEnSgAxjkiRJAzKMSZIkDcgwJkmSNCDDmCRJ0oAMY5IkSQMyjEmSJA1ovaELkLTm+OkFl/HHrzps6DKkRevkQ543dAlahGwZkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMkiRpQIYxSZKkARnGJEmSBmQYkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMkiRpQIYxSZKkARnGJEmSBmQYkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMkiRpQIYxSZKkARnGJEmSBmQYkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMkiRpQIYxSZKkARnGJEmSBmQYkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMkiRpQIYxSZKkARnGJEmSBmQYkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBTRTGktwhyb0XuhhJkqS1zZxhLMnewKnA0f3xzkmOWujCJEmS1gaTtIwdCDwIuAKgqk4FtlvAmiRJktYak4SxG6rqyrFptRDFSJIkrW3Wm2CenyT5M2DdJDsA+wPfWtiyJEmS1g6TtIy9FNgJuB74BHAV8LKFLEqSJGltMWfLWFX9FnhDv0mSJGkVmjOMJdkVeD2wZHT+qrrfwpUlSZK0dphkzNjHgFcBpwE3L2w5kiRJa5dJwtivq8rvFZMkSVoAk4SxNyX5APA12iB+AKrqMwtWlSRJ0lpikjC2L/CHwO1Y1k1ZgGFMkiRpJU0Sxh5YVf4upSRJ0gKY5HvGvpVkxwWvRJIkaS00ScvYQ4BTk5xLGzMWoPxqC0mSpJU3SRjbY8GrkCRJWkvN2U1ZVedX1fnA72gD96duc0ry3iQPX7kSl1vfy5LccSWWX5rkYWPT7prkK9PM++EkT5thPW9J8piVqGOfJG9I8oIkNbquJH/ap0277ZH5zktyWr+dnuRtSW4/y/wr9XuiSb6UZJuxaUuTfGGO5XZOstc8tnNykg2SbJrksCRnJTm73990guX/J8lmk25vgvU9MclrZ3l+aZIrk/wgyRlJvpHkCROs91bn4iqodbMkfz027egkV8z1OkmShjNnGOsXozOBc4HjgfOAL024/ocA31nh6m7tZcAKhzFgKTB+AdwD+PKkK0iyblW9saqOWYk69gSO7vdPA/YZee5ZwA8nXM+jquq+wIOA7YH/nKbe9QCqaoUv/EnuAPxBVV2wAovvDEwUxpJsB1xYVdcDHwTOqap7VtU9aOffB+ZaR1XtVVVXrECdM63vqKo6aI7ZTqiqXfoHXfYH3p3k0XMss5Rbn4srazPgr8emHQI8dxVvR5K0Ck3STflWWqg6pqp2SfIo4DlzLZTkj4CfVdVNSe4JvBe4M3AT8HTgHOBgWjAp4G1VdWSSpcCBwKXAfYCT+/ZeCmwFHJvk0qp6VJLHAW8GNgDOBvatqmuSnAd8BNib9pUcTweuA/YDbkryHOClVXUCLYy9OUmAQ4HHAr8Afj+yL+cBR/bnDk6yB/AF4BrgRVX19D7fUuCVVfWEWWoLLaCcAtwXOAHYLcnt+rz3BE7t6/u/wP5V9af98WOBv66qJ48e677e/YBfJLkTcL/+ul1O+1qSeyW5pqo2SnIE8NGq+mJf54f7vnwWOIgWEjYA3lNVU+FuKXBcn38P4N+A3wLfHDlGDwLeCdye1oq6Ly1AvQW4Q5JHAG/v05abr6rO6KvZAzi6ny9/DDxzZDffApyV5B7A3frjq/vxOrYfl5v7a7UrsBHtj4Zv0kLPhcCTqup3SXamnY937K/NC6vq8iT7086RG4HTq2qfJC8Adq2qlyR5OvAm2jl8ZVXtzpiqOjXJW4CXAF9LsjdwALA+cBnwbOAOjJ2LtCC13HxVdUmSR/bjBe3/ye5VdXWSVwHP6K/VZ6vqTf31u0eSU4GvVtWrqupr/byUJrLhmV9hnd9fO3QZi9bznrcyf6drSFtuuSUHH3zwINueJIzdUFWXJVknyTpVdWySf5tgudHWn48BB1XVZ3tX2jrAU2ih5P7AFsD3k3yjz78LsBNwEXAi8PCqeleSl9Nagy5NsgXt4vWYqro2yWuAl9Mu0gCXVtUDerfNK6vqxUneC1xTVf8MrZULuHdVnZ7kKcC9gR2BuwCnAx8a2Z/LquoBfbmpcXTHAO9LsmFVXUsLD0fMUdsuwA+rqlouo/p6Hg9sChwFbNfXfyzw70nuXFW/pgWc0ZpuUVVX9Q9Z7NAnPQC4T1WdOzbrkbSL+BeTrA88Gvgr4EW0gPHAJBsAJyb5Sl9+T+Bz/bV7P/B/gbP6uqb8L7BbVd3Yu13/saqemuSN9DDTj90m4/MBT+3r2AP4O1oIP7WqbhrZv5t6yNgJuIrWGrgjcD7tPHsK8Omxfd0BeFZV/XmST/btHA4cRgvjx/fg9CZaq+trge2q6voZujrfCDy+qi6coyv0FNpPiEELgw/pr/eLgVdX1SumORc3H58PeAXwSuBvqurEJBsB1/Wgv0M/BgGOSrJ7r/8+VbXzLLXdSpK/AP4CYP2N/2A+i+o2aJ3fX8u61181dBmL1oUXeuw0f5OEsSv6ReAbwMeS/AqY5M+mxwP7JtkY2LqqPgtQVdcB9JaST/QL7iVJjgceSLvQfm+qS6xfgJcw0grTPYR2MT6xh5r1gW+PPD/1pbQn0y7U03kw8N1+f/eRei5K8vWxeY8ce0wPFEcDeyf5NPAntIvoI2epbQ9u3c17BK17a1PaBfj1ff2V5KPAc5L8F/BQ4Hkz7Au0C/OU700TxOjbfmcPXHsA3+itRY8D7pdlY9U2pV3wzwUeTgsFOwLnVtWZAEkOp1/E+/wfSbIDLWDeboYap52vB8NtquqcJPeZZR9H9++cvuwngEdw6zB2blWd2u+fDCxJG3e2WVUd36d/BPhUv/8j2jn+OeBz02zzRODDPdjN9qXHo6/DNsCRSe5KOw+me01mm+9E4B1JPgZ8pqou6K/V44Af9Hk2or1WP5+lphlV1fuA9wFsuOV2E40H1W3XzetvOHQJi9rdt9h46BK0grbccsvBtj1JGHsSrYvv72hdLJuyrPVpWmmD7Derqot6GJuv60fu3zRDnaF1xTxrjnXMtDws33o3l5kC6BG0LqnfACf1LqTZanscy1qCAKiq7yW5L/DbqvpZD3BT/gv4PO01+FRV3ThdEf04LwF+RmttnLbeqrouyXG0sPzMXj+04/nSqlpu/FyS7YFfVNXvx+oa91bg2Kp6cpIl9G7Necy3G8sC9+nAzr0l9uZexzq0ltTTacFlPDRMFyLGz6M7zLYDtDC9O617+w39NVm2gar9kjy4z3dykj+eYT27AD/t9w8F3lFVR2VZF/x0pp2vqg5K8kXauLsTkzye9lq9faQbGYB+PKWVcu0Ojxu6hEXtsENm+3tZmt4kn6a8tqpuqqobq+ojVfWuqrpsjsUeRetio6quBi5IMjXuaYMe1k4Anplk3SR3pl0EvzfHeq8GpsLdd4CH9/FFJNkwyb3msTy0LrqpDv5vjNRz174Pkzie1iX45ywLNtPW1ltl1pvh+L2W3iI2qqouonXXHkALZrfSWy7/HfhcVV0+Qc1H0ro8d2NZGP0y8FdpY9fo9W7I8oH1f2mtS/foj0fD5qa0cVkALxiZPn7MZ5rvlhbDqjqL1upzwMjzBwCn9OcAHpRkux7SnsmtW06nVVVXApcn2a1Pei5wfF/P3arqWOA1vc6NRpdNco+q+m5VvRH4NW3sGmPz3A/4e+A90+zv80dmne243DJf3+ZpVfVPwPdpYwC/DLywv+4k2TrJ/5lmnZKkRWCST1M+JcmZaR/fvyrJ1Unm6hQfb3F6LrB/kh8B3wK2pA0Y/xHtk4Nfp42l+eUc630fbYD3sX0M1QuAT/T1fpt2oZrN54EnJzm1X4yv62GRXs+ZtJaXw1i+y3NGvVvzC7R9/kKfNlNtj2VZ+Btfz5d6EJjOx2itUz8dm35skh/TQuzPgb+cpGbgK7Su1GOqauqDCh+g7fspfZ3/SWtR3IP+WvYu5r+gjTc7BfjVyDoPBt6e5Acs3xJ5LLBjP+bPnGW+pbRgO+VFtA8enJ3kbOBefdqU7wPvprVAnUt7/Sb1fOCQ/trsTGvpXRc4PMlptCD4rrr1pzIPSfsqkR/TzuOpT73ulv7VFrQQtn9Vfa0/dyDwqSQn0z6UMmX8XJxpvpcl+XGv9QbgS1X1FeDjwLd7vZ8GNu4h/8Q+/yEASU6gdcM+OskFvWVNkrQGSdXsQ0SSnAXsPU0QmG2ZU4AHV9UNK1nfgkn7FNs2NffXFqzKbX4A+EBVzevrPpK8G/hBVX1wYSqbcbsbACdW1a4LvJ1tgPdX1Z4Tzr+U/qnVhaxrbbThltvVHz73zUOXIS1aJ9tNuVZKcvLKXCsnGTN2yXyCGMDUpw7XZFV1+ADbfPF8l+ktJdfSBvavVtW+72tBg1jfzgW0lkVJktY6k4Sxk5IcSft02S0Doqtqtk+TaRWpqpkGia+1quo4Zv6AgCRJi8okYWwT2hd8jn7Eppj9o/2SJEmawJxhrKr2XR2FSJIkrY0m+TTlvZJ8rX+CjCT3S3LAXMtJkiRpbnOGMdrP37yO9rF6qupHLP/D1pIkSVpBk4SxO1bV+JexTvst8JIkSZqfScLYpf0b1wug/3bhxQtalSRJ0lpikk9T/g3tm+//MMmFtG87f86CViVJkrSWmOTTlOcAj+m/U7jOyM8HSZIkaSXNGMaSvHyG6QBU1TsWqCZJkqS1xmwtYxuvtiokSZLWUjOGsary14IlSZIW2GzdlK+uqoOTHEr/JOWoqtp/QSuTJElaC8zWTfka4GDgbODy1VOOJEnS2mW2MHZJkq2AfYGlQFZLRZIkSWuR2cLYfwBfA7YHTh6ZHlq35fYLWJckSdJaYbYB/IcChyb5j6r6q9VYkyRJ0lpjzp9DMohJkiQtnEl+m1KSJEkLxDAmSZI0IMOYJEnSgAxjkiRJAzKMSZIkDcgwJkmSNCDDmCRJ0oAMY5IkSQMyjEmSJA3IMCZJkjQgw5gkSdKADGOSJEkDMoxJkiQNyDAmSZI0IMOYJEnSgAxjkiRJAzKMSZIkDcgwJkmSNCDDmCRJ0oAMY5IkSQMyjEmSJA3IMCZJkjQgw5gkSdKADGOSJEkDMoxJkiQNyDAmSZI0IMOYJEnSgAxjkiRJAzKMSZIkDcgwJkmSNCDDmCRJ0oAMY5IkSQMyjEmSJA3IMCZJkjQgw5gkSdKADGOSJEkDMoxJkiQNyDAmSZI0IMOYJEnSgAxjkiRJAzKMSZIkDcgwJkmSNCDDmCRJ0oAMY5IkSQMyjEmSJA3IMCZJkjQgw5gkSdKADGOSJEkDMoxJkiQNyDAmSZI0IMOYJEnSgAxjkiRJAzKMSZIkDcgwJkmSNCDDmCRJ0oAMY5IkSQMyjEmSJA3IMCZJkjQgw5gkSdKADGOSJEkDMoxJkiQNyDAmSZI0oPWGLkDSmuOPtvkDTjrkeUOXIUlrFVvGJEmSBmQYkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMkiRpQIYxSZKkARnGJEmSBmQYkyRJGpBhTJIkaUCGMUmSpAEZxiRJkgZkGJMkSRqQYUySJGlAhjFJkqQBGcYkSZIGlKoaugZJa4gkVwNnDF3HStgCuHToIlbCYq5/MdcOi7v+xVw7LO76p2rftqruvKIrWW/V1SPpNuCMqtp16CJWVJKTrH8Yi7l2WNz1L+baYXHXv6pqt5tSkiRpQIYxSZKkARnGJI1639AFrCTrH85irh0Wd/2LuXZY3PWvktodwC9JkjQgW8YkSZIGZBiTJEkakGFMWksk2SPJGUnOSvLaaZ7fIMmR/fnvJlky8tzr+vQzkjx+ddY9UsMK1Z9kSZLfJTm13967Bta+e5JTktyY5Gljzz0/yZn99vzVV/VyNaxM/TeNHPujVl/Vt2x/rtpfnuT0JD9K8rUk2448txiO/Wz1r+nHfr8kp/X6vplkx5HnFsN7zrT1r9B7TlV58+btNn4D1gXOBrYH1gd+COw4Ns9fA+/t9/cBjuz3d+zzbwBs19ez7iKqfwnw4zX82C8B7gccBjxtZPqdgHP6v5v3+5svlvr7c9es4cf+UcAd+/2/GjlvFsuxn7b+RXLsNxm5/0Tg6H5/sbznzFT/vN9zbBmT1g4PAs6qqnOq6vfAEcCTxuZ5EvCRfv/TwKOTpE8/oqqur/U0m2YAAATUSURBVKpzgbP6+lanlal/aHPWXlXnVdWPgJvHln088NWq+k1VXQ58FdhjdRQ9YmXqH9oktR9bVb/tD78DbNPvL5ZjP1P9Q5uk9qtGHm4ITH2icFG858xS/7wZxqS1w9bAL0YeX9CnTTtPVd0IXAn8wYTLLrSVqR9guyQ/SHJ8kt0WutiZ6urmc/wWy7Gfze2TnJTkO0n+dNWWNqf51v4i4EsruOxCWJn6YREc+yR/k+Rs4GBg//ksu8BWpn6Y53uOP4ck6bbuYuDuVXVZkj8GPpdkp7G/arVwtq2qC5NsD3w9yWlVdfbQRY1L8hxgV+CRQ9eyImaof40/9lX1HuA9Sf4MOAAYZGzeipqh/nm/59gyJq0dLgTuNvJ4mz5t2nmSrAdsClw24bILbYXr710dlwFU1cm0cSD3WvCKp6mrm8/xWyzHfkZVdWH/9xzgOGCXVVncHCaqPcljgDcAT6yq6+ez7AJbmfoXxbEfcQQw1Xq3aI79iFvqX6H3nNU5IM6bN2/D3Git4OfQBsNODUbdaWyev2H5AfCf7Pd3YvnBtOew+gfTrkz9d56qlzYY90LgTmtS7SPzfphbD+A/lzaAfPN+f7XVvgrq3xzYoN/fAjiTsUHQQ9dOCyhnAzuMTV8Ux36W+hfDsd9h5P7ewEn9/mJ5z5mp/nm/56y2HfPmzduwN2Av4Gf9jfsNfdpbaH9NA9we+BRtsOz3gO1Hln1DX+4MYM/FVD/wVOAnwKnAKcDea2DtD6SNSbmW1hr5k5FlX9j36Sxg3zX02E9bP/Aw4LR+ITsNeNEaWPsxwCX9/DgVOGqRHftp618kx/6dI/83j2Uk7CyS95xp61+R9xx/DkmSJGlAjhmTJEkakGFMkiRpQIYxSZKkARnGJEmSBmQYkyRJGpBhTJK0oJJ8IMmO85h/1yTv6vdfkOTd89ze6PJLkzxsfhVLq5c/hyRJWlBV9eJ5zn8ScNKKbCvJemPLLwWuAb61IuuTVgdbxiRJq0ySDZN8MckPk/w4yTOTHJdk1/78NUkOSfKTJMckeVB//pwkT+zzLE3yhWnWvXeS7/YfYD4myV369AOTfDTJicBHp5ZPsgTYD/i7JKcm2S3JuUlu15fbZPSxNBTDmCRpVdoDuKiq7l9V9wGOHnt+Q+DrVbUTcDXwNuCxwJNp324+m28CD6mqXWi/Bfjqked2BB5TVc+amlBV5wHvBf61qnauqhNov9H4J32WfYDPVNUN895LaRUyjEmSVqXTgMcm+acku1XVlWPP/55lAe004Pgehk4Dlsyx7m2ALyc5DXgV7TcMpxxVVb+boL4PAPv2+/sC/zXBMtKCMoxJklaZqvoZ8ABauHpbkjeOzXJDLfsdvpuB6/tyNzP3OOZDgXdX1X2Bv6T9HumUayes70RgSZKltB9z/vEky0kLyQH8kqRVJslWwG+q6vAkVwDzGrw/h02BC/v950+4zNXAJmPTDgM+Drx1FdUlrRRbxiRJq9J9ge8lORV4E21M2KpyIPCpJCcDl064zOeBJ08N4O/TPgZsDnxiFdYmrbAsay2WJOm2L8nTgCdV1XOHrkUCuyklSWuRJIcCewJ7DV2LNMWWMUmSpAE5ZkySJGlAhjFJkqQBGcYkSZIGZBiTJEkakGFMkiRpQP8f7BXXH6gmPMsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## 09. 한글 텍스트 처리 - 네이버 영화 평점 감성 분석"
      ],
      "metadata": {
        "id": "_ZHxpxaUPaeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **한글 NLP 처리의 어려움**\n",
        "\t* 띄어쓰기, 다양한 조사\n",
        "\n",
        "* **KoNLPy 소개**\n",
        "\t* 한글 형태소 패키지\n",
        "\t* 형태소 분석: 말뭉치를 형태소 어근 단위로 쪼개고 각 형태소에 품사 태깅을 부착하는 작업"
      ],
      "metadata": {
        "id": "bgTBSitjRE4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQzjjfHpetrc",
        "outputId": "7219687d-905d-404c-9b64-76ebe482dc40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 3.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tijoRVJ-V3EN",
        "outputId": "e22ff457-5f0b-4a37-a240-7ebfbb47ed88"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.0/449.0 KB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/data/0509/ratings_train.txt', sep='\\t')\n",
        "train_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "p9C_Td1YRzVe",
        "outputId": "cd6974a2-0203-4a6b-f5a5-e06baf084262"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                           document  label\n",
              "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a860954-46cf-47f6-b7fa-68ebde923a5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a860954-46cf-47f6-b7fa-68ebde923a5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a860954-46cf-47f6-b7fa-68ebde923a5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a860954-46cf-47f6-b7fa-68ebde923a5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'].value_counts( )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw3Z57k_R1Va",
        "outputId": "499992ef-71f9-4d9d-b3a1-6c3bf0695f96"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    75173\n",
              "1    74827\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "train_df = train_df.fillna(' ')\n",
        "# 정규 표현식을 이용하여 숫자를 공백으로 변경(정규 표현식으로 \\d 는 숫자를 의미함.) \n",
        "train_df['document'] = train_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n",
        "\n",
        "# 테스트 데이터 셋을 로딩하고 동일하게 Null 및 숫자를 공백으로 변환\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/data/0509/ratings_test.txt', sep='\\t')\n",
        "test_df = test_df.fillna(' ')\n",
        "test_df['document'] = test_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n",
        "\n",
        "# 개정판 소스 코드 변경(2019.12.24)\n",
        "train_df.drop('id', axis=1, inplace=True) \n",
        "test_df.drop('id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "tkyy8ynKR2oE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Twitter\n",
        "\n",
        "twitter = Twitter()\n",
        "def tw_tokenizer(text):\n",
        "    # 입력 인자로 들어온 text 를 형태소 단어로 토큰화 하여 list 객체 반환\n",
        "    tokens_ko = twitter.morphs(text)\n",
        "    return tokens_ko"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpI2ha4cR3t2",
        "outputId": "1d30c5ef-a92a-4c52-b74f-a26f876c0060"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Twitter 객체의 morphs( ) 객체를 이용한 tokenizer를 사용. ngram_range는 (1,2) \n",
        "tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
        "tfidf_vect.fit(train_df['document'])\n",
        "tfidf_matrix_train = tfidf_vect.transform(train_df['document'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ombNTFzXR3r3",
        "outputId": "8822248f-7fa6-472d-cc5d-eb3045b4c31c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression 을 이용하여 감성 분석 Classification 수행. \n",
        "lg_clf = LogisticRegression(random_state=0)\n",
        "\n",
        "# Parameter C 최적화를 위해 GridSearchCV 를 이용. \n",
        "params = { 'C': [1 ,3.5, 4.5, 5.5, 10 ] }\n",
        "grid_cv = GridSearchCV(lg_clf , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
        "grid_cv.fit(tfidf_matrix_train , train_df['label'] )\n",
        "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE7vz_S5R3p7",
        "outputId": "ee92d2e9-23a9-43e6-b223-b023ce987ccf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 3.5} 0.8593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 학습 데이터를 적용한 TfidfVectorizer를 이용하여 테스트 데이터를 TF-IDF 값으로 Feature 변환함. \n",
        "tfidf_matrix_test = tfidf_vect.transform(test_df['document'])\n",
        "\n",
        "# classifier 는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용\n",
        "best_estimator = grid_cv.best_estimator_\n",
        "preds = best_estimator.predict(tfidf_matrix_test)\n",
        "\n",
        "print('Logistic Regression 정확도: ',accuracy_score(test_df['label'],preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxGeIKdeR3na",
        "outputId": "93a77328-647c-4f66-b523-52507eb9f85e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression 정확도:  0.86186\n"
          ]
        }
      ]
    }
  ]
}